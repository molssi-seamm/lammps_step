# Configuration options for how to run LAMMPS

[docker]
# The code to use. This may maybe more than just the name of the code, and variables in
# braces {} will be expanded. For example:
#   code = mpirun -np {NTASKS} lmp
# would expand {NTASKS} to the number of tasks and run the command
#
# If you are running from a queueing system such as SLURM, if MPI was compiled
# to know about the batch system, you should be able to use something like
# 'srun' or 'mpirun' with no further arguments to run parallel tasks. If
# you are not lucky, and need the parameters, you can add them to the command
# line like this:
#
# code = mpirun -n {NTASKS} -H {NODELIST} -npernode {NTASKS_PER_NODE}

code = mpirun -n {NTASKS} lmp
python = python

# Optional command-line arguments for LAMMPS. These are usually used with accelerators
# such as Kokkos or GPU to automatically apply the accelerator. Again there is a normal
# and GPU version

# cmd-args = -k on -sf kk
# gpu-cmd-args = -k on g {ngpus} -sf kk -pk kokkos gpu/aware on newton on neigh full neigh/thread on neigh/transpose off comm device

# The name and location of the Docker container to use, optionally with the version

container = ghcr.io/molssi-seamm/seamm-lammps:{version}

# In addition, you can specify the platform to use. This is useful on e.g. Macs with
# app silicon (M1, M3...) where the default platform is linux/arm64 but some containers
# are only available for linux/amd64.

platform = linux/amd64

[local]
# The type of local installation to use. Options are:
#     conda: Use a conda environment
#   modules: Use the modules system
#     local: Use a local installation
#    docker: Use a Docker container
# By default SEAMM installs LAMMPS using conda.

installation = conda

# The command line to use, which should start with the executable followed by any options.
# Variables in braces {} will be expanded. For example:
#
#   code = mpirun -np {NTASKS} lmp
#
# would expand {NTASKS} to the number of tasks and run the command.
# For a 'local' installation, the command line should include the full path to the
# executable or it should be in the path. 
#
# If you are running from a queueing system such as SLURM, if MPI was compiled
# to know about the batch system, you should be able to use something like
# 'srun' or 'mpirun' with no further arguments to run parallel tasks. If
# you are not lucky, and need the parameters, you can add them to the command
# line like this:
#
# code = mpirun -n {NTASKS} -H {NODELIST} -npernode {NTASKS_PER_NODE}

code = mpirun -np {NTASKS} lmp
python = mpirun -np {NTASKS} python

# Optional command-line arguments for LAMMPS. These are usually used with accelerators
# such as Kokkos or GPU to automatically apply the accelerator. Again there is a normal
# and GPU version

# cmd-args = -k on -sf kk
# gpu-cmd-args = -k on g {ngpus} -sf kk -pk kokkos gpu/aware on newton on neigh full neigh/thread on neigh/transpose off comm device

######################### conda section ############################
# The full path to the conda executable:

# conda = 

# The Conda environment to use. This is either the name or full path.

# conda-environment = seamm-lammps

######################### modules section ############################
# The modules to load to run LAMMPS, as a list of strings.
# For example, to load the modules lammps and openmpi, you would use:
#   modules = lammps openmpi

# modules = 

######################### local section ############################
# The full path to the LAMMPS executable should be in the 'code' option.

######################### docker section ############################
# The name and location of the Docker container to use, optionally with the version.
# {version} will be expanded to the version of the plug-in.

# container = ghcr.io/molssi-seamm/seamm-lammps:{version}

# In addition, you can specify the platform to use. This is useful on e.g. Macs with
# app silicon (M1, M3...) where the default platform is linux/arm64 but some containers
# are only available for linux/amd64.

platform = linux/amd64
